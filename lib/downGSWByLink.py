# downList.py

import os
import urllib.request
import sys
import re
from urllib.parse import urljoin, urlparse
from lxml import etree
from docx import Document
from docx.shared import Pt, Cm, RGBColor
from docx.oxml.ns import qn
from docx.enum.text import WD_PARAGRAPH_ALIGNMENT
import time
import random
from lib import downGSW

# å°è¯•å¯¼å…¥ configï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ print æ›¿ä»£
try:
    import lib.config as config
except ImportError:

    class config:
        @staticmethod
        def setLog(msg):
            print(f"[LOG] {msg}")


num = 0


def progressbar(cur, total=100):
    percent = "{:.2%}".format(cur / total)
    sys.stdout.write("\r")
    sys.stdout.write("[%-100s] %s" % ("=" * int(cur), percent))
    sys.stdout.flush()


def schedule(blocknum, blocksize, totalsize):
    if totalsize == 0:
        percent = 0
    else:
        percent = blocknum * blocksize / totalsize
    if percent > 1.0:
        percent = 1.0
    percent = percent * 100
    progressbar(percent)


class down:
    def __init__(self, url):
        self.url = url
        self.base_domain = self.get_base_domain(url) if url else ""
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
            "Connection": "keep-alive",
        }
        self.book_info = {"title": "æœªçŸ¥ä¹¦å", "desc": "ç®€ä»‹ï¼šæ— "}
        self.temp_path = os.path.join("ä¸‹è½½", "temp_book.html")
        print("ğŸ“˜ å¼€å§‹ä¸‹è½½ä¹¦ç±ç›®å½•...")
        self.downFile()

    def get_base_domain(self, url):
        parsed = urlparse(url)
        return f"{parsed.scheme}://{parsed.netloc}"

    def downFile(self):
        # åˆ›å»ºç›®å½•
        os.makedirs("ä¸‹è½½", exist_ok=True)

        # ä¸‹è½½ä¸»é¡µ
        opener = urllib.request.build_opener()
        opener.addheaders = [("User-Agent", self.headers["User-Agent"])]
        urllib.request.install_opener(opener)
        try:
            urllib.request.urlretrieve(self.url, self.temp_path, schedule)
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            return

        # è§£æç« èŠ‚
        articles = self.downList()
        
        if not articles:
            config.setLog("âŒ æœªè§£æåˆ°ç« èŠ‚åˆ—è¡¨")
            return

        print(f"\nğŸ” å…±æ‰¾åˆ° {len(articles)} ç« ï¼Œå¼€å§‹æŠ“å–...")

        # æ¸…ç©ºæ—§å†…å®¹
        downGSW.clear_content()

        # é€ç« æŠ“å–
        for idx, item in enumerate(articles):
            print(f"[{idx+1:2d}/{len(articles)}] {item['title']}")
            downGSW.down(item["title"], item["link"])
            time.sleep(random.uniform(2.0, 4.0))  # é˜²çˆ¬å»¶è¿Ÿ 2-4sä¹‹é—´

        # åˆå¹¶ä¿å­˜
        all_content = downGSW.get_all_content()
        self.save_all_to_one_docx(all_content)
         # âœ… åœ¨è¿™é‡Œåˆ é™¤ä¸´æ—¶æ–‡ä»¶ï¼ˆå·²ç»ä¸éœ€è¦äº†ï¼‰
        try:
            if os.path.exists(self.temp_path):
                os.remove(self.temp_path)
                print(f"ğŸ—‘ï¸ ä¸´æ—¶æ–‡ä»¶å·²åˆ é™¤: {self.temp_path}")
        except Exception as e:
            print(f"âš ï¸ åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")

    def parse_js_array(self, file_content):
        html = etree.HTML(file_content)
        a_nodes = html.xpath('//a[contains(@href,"bookv_")]')
        chapters = []
        for a in a_nodes:
            href = a.get("href")
            title = a.text.strip() if a.text else ""
            if title and "guwen" in href:
                full_url = urljoin("https://www.gushiwen.cn", href)
                chapters.append({"title": title, "link": full_url})
        return chapters

    def downList(self):
        try:
            with open(self.temp_path, "r", encoding="utf-8") as f:
                content = f.read()

            # æå–ä¹¦å
            tree = etree.HTML(content)
            title_node = tree.xpath('//div[@class="main3"]//h1//b/text()')
            desc_node = tree.xpath('//div[@class="main3"]//div[@class="cont"]/p//text()')
            intro = ''.join([
                    text.strip() 
                    for text in desc_node 
                    if not text.strip().startswith('â–º')
                ]).strip()
            if title_node:
                self.book_info["title"] = title_node[0].strip()
            if intro:
                 self.book_info["desc"] = intro.strip()
            # è§£æç« èŠ‚
            articles = self.parse_js_array(content)

            if not articles:
                config.setLog("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆç« èŠ‚é“¾æ¥")
                return None
            # articles = articles[20:21] #æµ‹è¯•
            # articles = articles[:1] #æµ‹è¯•
            return articles

        except Exception as e:
            config.setLog(f"âŒ è§£æå¤±è´¥: {str(e)}")
            return None

    def save_all_to_one_docx(self, chapters_data):
        """å°†æ‰€æœ‰ç« èŠ‚åˆå¹¶ä¿å­˜ä¸ºä¸€ä¸ª Word æ–‡ä»¶ï¼Œæ»¡è¶³ï¼šæ ‡é¢˜æ¥·ä½“ï¼Œæ­£æ–‡æ®µå0.2è¡Œï¼Œè¡Œè·1.5å€"""
        doc = Document()

        # -------------------------------
        # è®¾ç½®é»˜è®¤æ ·å¼ï¼ˆNormalï¼‰
        # -------------------------------
        style = doc.styles["Normal"]
        font = style.font
        font.name = "æ¥·ä½“"
        font.size = Pt(12)
        font.color.rgb = RGBColor(0, 0, 0)
        font._element.rPr.rFonts.set(qn("w:eastAsia"), "æ¥·ä½“")

        # -------------------------------
        # è‡ªå®šä¹‰â€œæ ‡é¢˜1â€æ ·å¼ï¼ˆæ ‡é¢˜ï¼šæ¥·ä½“ã€é»‘è‰²ã€å°äºŒã€åŠ ç²—ã€å±…ä¸­ï¼‰
        # -------------------------------
        try:
            heading_style = doc.styles["Heading 1"]
        except KeyError:
            from docx.enum.style import WD_STYLE_TYPE

            heading_style = doc.styles.add_style("Heading 1", WD_STYLE_TYPE.PARAGRAPH)

        # æ®µè½æ ¼å¼
        heading_format = heading_style.paragraph_format
        heading_format.space_before = Pt(24)
        heading_format.space_after = Pt(24)
        heading_format.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER

        # å­—ä½“æ ¼å¼
        font = heading_style.font
        font.name = "æ¥·ä½“"
        font.size = Pt(18)  # å°äºŒ
        font.bold = True
        font.color.rgb = RGBColor(0, 0, 0)
        font._element.rPr.rFonts.set(qn("w:eastAsia"), "æ¥·ä½“")

        # -------------------------------
        # ä¹¦åï¼ˆä½¿ç”¨ Heading 1ï¼‰
        # -------------------------------
        p0 = doc.add_paragraph()
        p0.alignment = WD_PARAGRAPH_ALIGNMENT.LEFT
        p0.add_run(self.book_info["title"])
        p0.line_spacing = 1.5  # è¡Œè· 1.5 å€
       
        # ç®€ä»‹
        pDesc = doc.add_paragraph()
        pDesc.alignment = WD_PARAGRAPH_ALIGNMENT.LEFT
        pDesc.add_run(self.book_info["desc"])
        pDesc.line_spacing = 1.5  # è¡Œè· 1.5 å€
        # æ·»åŠ åˆ†é¡µç¬¦
        doc.add_page_break()
        # æ·»åŠ ç©ºè¡Œ

        # -------------------------------
        # é€ç« å†™å…¥å†…å®¹
        # -------------------------------
        for idx, (combined, paragraphs) in enumerate(chapters_data):
            # ç« èŠ‚æ ‡é¢˜
            p_title = doc.add_paragraph(style="Heading 1")
            p_title.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER

            run_title = p_title.add_run(combined)

            # âœ… è®¾ç½®å­—ä½“ä¸ºæ¥·ä½“ï¼ˆå…³é”®ï¼šå¿…é¡»è®¾ç½® eastAsiaï¼‰
            run_title.font.name = "æ¥·ä½“"
            run_title.font._element.rPr.rFonts.set(qn("w:eastAsia"), "æ¥·ä½“")

            # âœ… è®¾ç½®é¢œè‰²ä¸ºé»‘è‰²
            run_title.font.color.rgb = RGBColor(0, 0, 0)


            # æ­£æ–‡æ®µè½
            for para in paragraphs:
                p = doc.add_paragraph()
                p_format = p.paragraph_format
                p_format.space_before = Pt(0)  # æ®µå‰é—´è· 0
                p_format.space_after = Pt(
                    0.2
                )  # æ®µåé—´è· â‰ˆ 0.2 è¡Œï¼ˆå°å››12ptï¼Œ0.2*12=2.4ptï¼Œç•¥ä¸Šæµ®ï¼‰
                p_format.line_spacing = 1.5  # è¡Œè· 1.5 å€
                p_format.first_line_indent = Cm(0.74)  # é¦–è¡Œç¼©è¿› 2 å­—ç¬¦

                run = p.add_run(para['content'].strip())
                run.font.name = "æ¥·ä½“"
                run.font.color.rgb = RGBColor(0, 0, 0)
                run._element.rPr.rFonts.set(qn("w:eastAsia"), "æ¥·ä½“") 
                if para['type'] == 'text':
                    run.font.size = Pt(12)
                else:
                    run.font.size = Pt(16)
                    run.bold = True

                

            # æ¯ç« ååŠ åˆ†é¡µ
            if idx < len(chapters_data) - 1:  # idx ä» 0 å¼€å§‹ï¼Œæœ€åä¸€ç« çš„ idx = len-1
                doc.add_page_break()

        # -------------------------------
        # ä¿å­˜æ–‡ä»¶
        # -------------------------------
        safe_title = re.sub(r'[<>:"/\\|?*\x00]', "", self.book_info["title"])
        output_dir = os.path.join("ä¸‹è½½")
        os.makedirs(output_dir, exist_ok=True)
        output_path = os.path.join(output_dir, f"{safe_title}.docx")

        try:
            doc.save(output_path)
            print(f"\nğŸ‰ æˆåŠŸä¿å­˜ï¼š{output_path}")
            config.setLog(
                f"ã€{safe_title}ã€‘å…¨æœ¬ä¸‹è½½å®Œæˆï¼Œå…± {len(chapters_data)} ç« ï¼Œå·²æŒ‰æ ¼å¼æ’ç‰ˆ"
            )
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
            config.setLog(f"ä¿å­˜å¤±è´¥: {str(e)}")


# =============================
# ä½¿ç”¨ç¤ºä¾‹ï¼ˆå–æ¶ˆæ³¨é‡Šå¹¶å¡«å†™ç½‘å€å³å¯è¿è¡Œï¼‰
# =============================
# if __name__ == "__main__":
#     url = "https://www.gushiwen.cn/guwen/bookv_XXXXXXXX.aspx"
#     downloader = down(url)
